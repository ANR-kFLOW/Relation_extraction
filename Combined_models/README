Building from a docker file locally: 
The file can either have the repository for the app stored locally on the machine or in the image.

If it is prefered to have all of the files in the image add these lines to Docker file for the first image:
WORKDIR /app
# Copy the files into the new image
COPY Combined_model/ /app/Combined_model/

Be sure to have the Combined_model folder saved on your local machine.
After the Docker image is built the Combined_model folder can be removed and the folder will be stored in the image.

For having the information stored locally in your machine you can just download the Combined_models folder,
and mount it to the docker image with the command: docker run -p 5001:5004 -it -v $(pwd)/Combined_model:/data relation_extraction_pipeline 

Using the docker file from the docker testing folder build the image with the command: 
docker build --platform linux/amd64  -t relation_extraction docker-testing/Dockerfile

or alternatively from within the docker-testing folder:
docker build --platform linux/amd64  -t relation_extraction

then run the image with: docker run -it relation_extraction
inside the docker use the following commands in the following order:
conda install anaconda::evaluate
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia 
conda install anaconda::scikit-learn     
conda install conda-forge::transformers 
conda install conda-forge::accelerate
conda install conda-forge::langchain
conda install conda-forge::python-dotenv 
conda install anaconda::flask
conda install conda-forge::werkzeug=2.2
conda install conda-forge::openai=0.28.1
conda install conda-forge::huggingface_hub
conda install conda-forge::flask-swagger-ui
conda install conda-forge::flask-restful

After this is over commit the image into another image that is based on this instance with the name relation_extraction_pipeline 

docker commit [Name of Docker instance]  relation_extraction_pipeline

To be able to connect to the application you need to export the docker file to a local port that is available. 

In this example the local port for 5001 is available:
docker run -p 5001:5004 -it -v $(pwd)/Combined_model:/data relation_extraction_pipeline 

When running the link that is given in the terminal change the local port number to the number that you exported from your local machine. 
for the previous example it would be http://127.0.0.1:5001/swagger/

Be sure to add the /swagger to the end of the link. 







Pretrained Models storage and directory pathing: 
The heirarchy for storing the pretrained models should look like
pretrained_models:
  st0:
    roberta_st0:
      pretrained_model.pt
  st1:
    roberta_st1:
      pretrained_model_folder
  st2:
    roberta_st2:
      pretrained_model_folder
  st3:
    LLM_st3:
      nothing so far
    rebel_st3:
      pretrained_model.pth

St0: filters out the entries that have no relationship
St1: classifies the type of relationship in a given entry
St2: gives the subject and the object of a given relationship for each entry
St3: these models output a combination of St1 and St2

In the options St3 models can be used to do either st1 or st2 tasks, however when the model is called both tasks are done regardless if the pipeline requests for only one.
So far the LLM_st3 options do not require anything from the folder but it is still kept because a future LLM might need something stored in there.

All of the place holder names would have to be replaced with a counterpart that is compatible with the script that runs the model. 
When putting in files into st0 or rebel_st3 be mindful of keeping the file as the same file type as shown in the example. 

When putting in multiple pretrained model files in the same directory make sure that each name is unique so that it can be clearly distinguished when the model appears as an option in the web application.



When importing this github be sure to create the empty folders: saved_app_outs and combined_outs
